{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c591793",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b13f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "### LangSmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0958fd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True} client=<openai.resources.chat.completions.completions.Completions object at 0x14954aab0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1098bb5f0> root_client=<openai.OpenAI object at 0x149ab1520> root_async_client=<openai.AsyncOpenAI object at 0x149a823c0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********') stream_usage=True\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be5b71d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Generative AI refers to a category of artificial intelligence systems that are designed to generate new content. These systems learn patterns from existing data and use that information to create original outputs. Generative AI can be applied in various fields, including text, images, music, and more.\\n\\nSome key technologies and models within generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs):** These involve two neural networks, a generator and a discriminator, that work against one another. The generator attempts to create data that mimics real data, while the discriminator evaluates the authenticity of the data. Over time, the generator improves in creating realistic content.\\n\\n2. **Variational Autoencoders (VAEs):** These are used primarily for generating data that reflects the distribution of the training data set. They work by encoding input data to a latent space and then decoding it back to the original dimension.\\n\\n3. **Transformer Models:** Particularly those using the architecture of models like GPT (Generative Pre-trained Transformer), which are designed to generate text. These models have been very successful in generating coherent and contextually relevant text based on a given input.\\n\\n4. **Diffusion Models:** Recently popular for generating high-quality images, these models start with a random distribution and gradually refines the image through a series of steps.\\n\\nGenerative AI has numerous applications, including creating realistic images and videos, composing music, designing products, writing articles, and even developing new drug formulations. However, it also raises important ethical and societal questions, such as the potential for misuse in creating deepfakes or the impact on creative industries.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 323, 'prompt_tokens': 13, 'total_tokens': 336, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_672b6a21ba', 'id': 'chatcmpl-CjJ9Cdaczglbq97uVOl4Wz0g6wLv6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--bd88b8fc-96fa-48cb-8846-d20e605a0f79-0', usage_metadata={'input_tokens': 13, 'output_tokens': 323, 'total_tokens': 336, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Input and get reponse from LLM\n",
    "\n",
    "result = llm.invoke(\"What is generative AI?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b793b0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI refers to a category of artificial intelligence systems that are designed to generate new content. These systems learn patterns from existing data and use that information to create original outputs. Generative AI can be applied in various fields, including text, images, music, and more.\n",
      "\n",
      "Some key technologies and models within generative AI include:\n",
      "\n",
      "1. **Generative Adversarial Networks (GANs):** These involve two neural networks, a generator and a discriminator, that work against one another. The generator attempts to create data that mimics real data, while the discriminator evaluates the authenticity of the data. Over time, the generator improves in creating realistic content.\n",
      "\n",
      "2. **Variational Autoencoders (VAEs):** These are used primarily for generating data that reflects the distribution of the training data set. They work by encoding input data to a latent space and then decoding it back to the original dimension.\n",
      "\n",
      "3. **Transformer Models:** Particularly those using the architecture of models like GPT (Generative Pre-trained Transformer), which are designed to generate text. These models have been very successful in generating coherent and contextually relevant text based on a given input.\n",
      "\n",
      "4. **Diffusion Models:** Recently popular for generating high-quality images, these models start with a random distribution and gradually refines the image through a series of steps.\n",
      "\n",
      "Generative AI has numerous applications, including creating realistic images and videos, composing music, designing products, writing articles, and even developing new drug formulations. However, it also raises important ethical and societal questions, such as the potential for misuse in creating deepfakes or the impact on creative industries.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98f7aebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ffc80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"LangSmith is a suite of tools crafted by the team behind LangChain, designed to enhance the development and deployment of language model applications. It offers monitoring, testing, tracing, and debugging capabilities for applications that use large language models (LLMs). This is crucial given the inherent complexity and unpredictability involved in working with LLMs.\\n\\nOne of LangSmith's standout features is its integration with the LangChain framework, which is already widely used for building language model pipelines. LangSmith builds on this by providing observability tools to monitor and trace requests, thus enabling developers to optimize and refine their applications more effectively. Additionally, it supports the creation of test suites tailored for LLM applications, helping developers ensure performance and functionality before deploying to production.\\n\\nOverall, LangSmith serves as a pivotal resource for developers looking to build robust, reliable, and efficient language model-driven applications.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 173, 'prompt_tokens': 33, 'total_tokens': 206, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_672b6a21ba', 'id': 'chatcmpl-CjJRDDguJ4gXBOlF4oabKd4slz60w', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--744eff90-9dab-480b-a9a0-2ac8145aae82-0', usage_metadata={'input_tokens': 33, 'output_tokens': 173, 'total_tokens': 206, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chain \n",
    "chain = prompt|llm\n",
    "\n",
    "response = chain.invoke({\"input\":\"Can you tell me about LangSmith?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0605bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith is a suite of tools crafted by the team behind LangChain, designed to enhance the development and deployment of language model applications. It offers monitoring, testing, tracing, and debugging capabilities for applications that use large language models (LLMs). This is crucial given the inherent complexity and unpredictability involved in working with LLMs.\n",
      "\n",
      "One of LangSmith's standout features is its integration with the LangChain framework, which is already widely used for building language model pipelines. LangSmith builds on this by providing observability tools to monitor and trace requests, thus enabling developers to optimize and refine their applications more effectively. Additionally, it supports the creation of test suites tailored for LLM applications, helping developers ensure performance and functionality before deploying to production.\n",
      "\n",
      "Overall, LangSmith serves as a pivotal resource for developers looking to build robust, reliable, and efficient language model-driven applications.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f45aace2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c36c9137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith is a tool developed by the team behind LangChain, designed to facilitate the development, evaluation, and deployment of AI applications, particularly those that integrate components like Language Model Generations (LLMs), prompts, and chains. LangSmith provides a versatile platform for developers to manage and optimize their AI applications by offering capabilities such as instrumenting and tracking application performance, debugging outputs, and seamlessly handling tasks like prompt engineering.\n",
      "\n",
      "With LangSmith, developers can interact with and deploy their applications more efficiently, thanks to features that simplify testing and iteration. It is also designed to integrate smoothly with other tools in the LangChain ecosystem, enhancing the development workflow for AI-driven solutions. This tool is particularly useful for those looking to refine their language model outputs and ensure reliable application functionality.\n"
     ]
    }
   ],
   "source": [
    "## String Output Parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt|llm|output_parser\n",
    "\n",
    "response = chain.invoke({\"input\":\"Can you tell me about LangSmith?\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
